{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test 2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Florian-toll/toll/blob/master/test_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj5KGAQmh7OH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFeqpFZ7b8S6",
        "outputId": "19e238a2-603a-4836-f136-71b7095eeb04"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "!ls\n",
        "%cd \"gdrive/MyDrive/Datasets\"\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "gdrive\tsample_data\n",
            "/content/gdrive/MyDrive/Datasets\n",
            "closed-input  no_face-input  open-input\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFAqdKlmLCN5",
        "outputId": "88a84c50-3618-41e5-93ec-79be0e8a8034"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# number of learnings should be until the loss converges otherwise we overfit\n",
        "EPOCHS = 30\n",
        "IMG_WIDTH = 30\n",
        "IMG_HEIGHT = 30\n",
        "NUM_CATEGORIES = 3\n",
        "# number of images getting used for testing not for training in percent\n",
        "TEST_SIZE = 0.4\n",
        "# drop out nodes at random to make the network more robust\n",
        "DROPOUT = 0.5\n",
        "NORMALIZE = True\n",
        "HIDDENLAYERS_SIZE = 64\n",
        "# batchsize = x -> could define one // woundn't use it except if it takes to long\n",
        "# it is the amount of images in the data set which is getting looked at before an adjustment\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Get image arrays and labels for all image files\n",
        "    images, labels = load_data(os.getcwd())\n",
        "    print(labels)\n",
        "    # Split data into training and testing sets\n",
        "    labels = tf.keras.utils.to_categorical(labels)\n",
        "    x_train, x_test, y_train, y_test = train_test_split(\n",
        "        np.array(images), np.array(labels), test_size=TEST_SIZE\n",
        "    )\n",
        "    # Get a compiled neural network\n",
        "    model = get_model()\n",
        "    # Fit model on training data\n",
        "    model.fit(x_train, y_train, epochs=EPOCHS)\n",
        "\n",
        "    # Evaluate neural network performance\n",
        "    model.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "    # Save model to file\n",
        "    if len(sys.argv) == 3:\n",
        "        filename = sys.argv[2]\n",
        "        #model.save(filename)\n",
        "        #print(f\"Model saved to {filename}.\")\n",
        "\n",
        "def load_data(data_dir):\n",
        "    \"\"\"\n",
        "    Load image data from directory `data_dir`.\n",
        "\n",
        "    Assume `data_dir` has one directory named after each category, numbered\n",
        "    0 through NUM_CATEGORIES - 1. Inside each category directory will be some\n",
        "    number of image files.\n",
        "\n",
        "    Return tuple `(images, labels)`. `images` should be a list of all\n",
        "    of the images in the data directory, where each image is formatted as a\n",
        "    numpy ndarray with dimensions IMG_WIDTH x IMG_HEIGHT x 3. `labels` should\n",
        "    be a list of integer labels, representing the categories for each of the\n",
        "    corresponding `images`.\n",
        "    \"\"\"\n",
        "    images = list()\n",
        "    labels = list()\n",
        "\n",
        "    # get currend directory\n",
        "    #workingDirectory = os.getcwd()\n",
        "\n",
        "    # add them together\n",
        "    #path = workingDirectory + os.sep + data_dir\n",
        "    path = data_dir\n",
        "    # loop over all the directories\n",
        "    for dirpath, dirnames, filenames in os.walk(path):\n",
        "        print(\"x\")\n",
        "        if(filenames != ['.DS_Store']):\n",
        "            # loops over all the files inside the directory\n",
        "            for curFile in filenames:\n",
        "                if(curFile != '.DS_Store' and curFile != 'a'):\n",
        "                    file = dirpath + os.sep + curFile\n",
        "                    # reads the image\n",
        "                    image = cv2.imread(file)\n",
        "                    # rezeises the image\n",
        "                    resized = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT),\n",
        "                                        interpolation=cv2.INTER_AREA)\n",
        "                    # make the input better for the neural network\n",
        "                    if(NORMALIZE):\n",
        "                        resized = resized / 255.0\n",
        "                    # add to pictures\n",
        "                    images.append(resized)\n",
        "                    # add to labels\n",
        "                    if (dirpath == \"/content/gdrive/MyDrive/Datasets/closed-input\"):\n",
        "                        labels.append(0)\n",
        "                    if (dirpath == \"/content/gdrive/MyDrive/Datasets/no_face-input\"):\n",
        "                        labels.append(1)\n",
        "                    if (dirpath == \"/content/gdrive/MyDrive/Datasets/open-input\"):\n",
        "                        labels.append(2)\n",
        "    return(images, labels)\n",
        "\n",
        "def get_model():\n",
        "    \"\"\"\n",
        "    Returns a compiled convolutional neural network model. Assume that the\n",
        "    `input_shape` of the first layer is `(IMG_WIDTH, IMG_HEIGHT, 3)`.\n",
        "    The output layer should have `NUM_CATEGORIES` units, one for each category.\n",
        "    \"\"\"\n",
        "    INPUT_SHAPE = (IMG_WIDTH, IMG_HEIGHT, 3)\n",
        "    # bias\n",
        "    model = tf.keras.models.Sequential([\n",
        "        # add the convolution layer\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\",\n",
        "                               input_shape=INPUT_SHAPE),\n",
        "        # use pooling\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        # add another concolutional layer\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
        "        # pool again\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        # generate a form as an input layer\n",
        "        tf.keras.layers.Flatten(),\n",
        "        # dense all are connected -> smaller then the imput layer\n",
        "        tf.keras.layers.Dense(HIDDENLAYERS_SIZE, activation='relu'),\n",
        "        # add a dropout\n",
        "        tf.keras.layers.Dropout(DROPOUT),\n",
        "        # add the output layer\n",
        "        tf.keras.layers.Dense(NUM_CATEGORIES, \"softmax\")\n",
        "    ])\n",
        "    # compile the model\n",
        "    model.compile(\n",
        "        optimizer=\"adam\",\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x\n",
            "x\n",
            "x\n",
            "x\n",
            "x\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
            "Epoch 1/30\n",
            "49/49 [==============================] - 4s 79ms/step - loss: 0.7254 - accuracy: 0.7729\n",
            "Epoch 2/30\n",
            "49/49 [==============================] - 4s 78ms/step - loss: 0.6776 - accuracy: 0.7807\n",
            "Epoch 3/30\n",
            "49/49 [==============================] - 4s 78ms/step - loss: 0.6575 - accuracy: 0.7853\n",
            "Epoch 4/30\n",
            "49/49 [==============================] - 4s 78ms/step - loss: 0.6895 - accuracy: 0.7807\n",
            "Epoch 5/30\n",
            "49/49 [==============================] - 4s 78ms/step - loss: 0.6254 - accuracy: 0.7925\n",
            "Epoch 6/30\n",
            "49/49 [==============================] - 4s 77ms/step - loss: 0.6313 - accuracy: 0.7951\n",
            "Epoch 7/30\n",
            "49/49 [==============================] - 4s 78ms/step - loss: 0.6418 - accuracy: 0.7912\n",
            "Epoch 8/30\n",
            "49/49 [==============================] - 4s 78ms/step - loss: 0.6177 - accuracy: 0.7996\n",
            "Epoch 9/30\n",
            "49/49 [==============================] - 4s 78ms/step - loss: 0.5941 - accuracy: 0.8016\n",
            "Epoch 10/30\n",
            "49/49 [==============================] - 4s 78ms/step - loss: 0.5803 - accuracy: 0.8061\n",
            "Epoch 11/30\n",
            "49/49 [==============================] - 4s 78ms/step - loss: 0.5766 - accuracy: 0.8120\n",
            "Epoch 12/30\n",
            "49/49 [==============================] - 4s 77ms/step - loss: 0.6577 - accuracy: 0.7801\n",
            "Epoch 13/30\n",
            "49/49 [==============================] - 4s 77ms/step - loss: 0.5603 - accuracy: 0.8152\n",
            "Epoch 14/30\n",
            "49/49 [==============================] - 4s 77ms/step - loss: 0.5939 - accuracy: 0.8107\n",
            "Epoch 15/30\n",
            "49/49 [==============================] - 4s 77ms/step - loss: 0.5527 - accuracy: 0.8146\n",
            "Epoch 16/30\n",
            "49/49 [==============================] - 4s 77ms/step - loss: 0.5392 - accuracy: 0.8094\n",
            "Epoch 17/30\n",
            "49/49 [==============================] - 4s 77ms/step - loss: 0.5269 - accuracy: 0.8224\n",
            "Epoch 18/30\n",
            "49/49 [==============================] - 4s 78ms/step - loss: 0.5086 - accuracy: 0.8217\n",
            "Epoch 19/30\n",
            "49/49 [==============================] - 4s 77ms/step - loss: 0.5143 - accuracy: 0.8191\n",
            "Epoch 20/30\n",
            "49/49 [==============================] - 4s 77ms/step - loss: 0.5086 - accuracy: 0.8230\n",
            "Epoch 21/30\n",
            "49/49 [==============================] - 4s 78ms/step - loss: 0.4791 - accuracy: 0.8282\n",
            "Epoch 22/30\n",
            "49/49 [==============================] - 4s 78ms/step - loss: 0.4801 - accuracy: 0.8276\n",
            "Epoch 23/30\n",
            "49/49 [==============================] - 4s 78ms/step - loss: 0.4672 - accuracy: 0.8282\n",
            "Epoch 24/30\n",
            "49/49 [==============================] - 4s 78ms/step - loss: 0.4390 - accuracy: 0.8386\n",
            "Epoch 25/30\n",
            "49/49 [==============================] - 4s 78ms/step - loss: 0.4239 - accuracy: 0.8412\n",
            "Epoch 26/30\n",
            "49/49 [==============================] - 4s 77ms/step - loss: 0.4109 - accuracy: 0.8491\n",
            "Epoch 27/30\n",
            "49/49 [==============================] - 4s 78ms/step - loss: 0.3992 - accuracy: 0.8497\n",
            "Epoch 28/30\n",
            "49/49 [==============================] - 4s 78ms/step - loss: 0.3877 - accuracy: 0.8445\n",
            "Epoch 29/30\n",
            "49/49 [==============================] - 4s 78ms/step - loss: 0.3936 - accuracy: 0.8452\n",
            "Epoch 30/30\n",
            "49/49 [==============================] - 4s 78ms/step - loss: 0.3480 - accuracy: 0.8582\n",
            "33/33 - 1s - loss: 0.5894 - accuracy: 0.7982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nnh6nrw2rT4d",
        "outputId": "19c6526e-eeaa-4c4d-9555-d23c7228a444"
      },
      "source": [
        "a = list()\n",
        "a.append(1)\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS1ny7xyAw-F"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# number of learnings should be until the loss converges otherwise we overfit\n",
        "EPOCHS = 10\n",
        "IMG_WIDTH = 30\n",
        "IMG_HEIGHT = 30\n",
        "NUM_CATEGORIES = 43\n",
        "# number of images getting used for testing not for training in percent\n",
        "TEST_SIZE = 0.4\n",
        "# drop out nodes at random to make the network more robust\n",
        "DROPOUT = 0.5\n",
        "NORMALIZE = True\n",
        "HIDDENLAYERS_SIZE = 512\n",
        "# batchsize = x -> could define one // woundn't use it except if it takes to long\n",
        "# it is the amount of images in the data set which is getting looked at before an adjustment\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    old\n",
        "    # Check command-line arguments\n",
        "    #if len(sys.argv) not in [2, 3]:\n",
        "    #    sys.exit(\"Usage: python traffic.py data_directory [model.h5]\")\n",
        "    \"\"\"\n",
        "\n",
        "    # Get image arrays and labels for all image files\n",
        "    images, labels = load_data(sys.argv[1])\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    labels = tf.keras.utils.to_categorical(labels)\n",
        "    x_train, x_test, y_train, y_test = train_test_split(\n",
        "        np.array(images), np.array(labels), test_size=TEST_SIZE\n",
        "    )\n",
        "    # Get a compiled neural network\n",
        "    model = get_model()\n",
        "    # Fit model on training data\n",
        "    model.fit(x_train, y_train, epochs=EPOCHS)\n",
        "\n",
        "    # Evaluate neural network performance\n",
        "    model.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "    # Save model to file\n",
        "    if len(sys.argv) == 3:\n",
        "        filename = sys.argv[2]\n",
        "        model.save(filename)\n",
        "        print(f\"Model saved to {filename}.\")\n",
        "\n",
        "\n",
        "def load_data(data_dir):\n",
        "    \"\"\"\n",
        "    Load image data from directory `data_dir`.\n",
        "\n",
        "    Assume `data_dir` has one directory named after each category, numbered\n",
        "    0 through NUM_CATEGORIES - 1. Inside each category directory will be some\n",
        "    number of image files.\n",
        "\n",
        "    Return tuple `(images, labels)`. `images` should be a list of all\n",
        "    of the images in the data directory, where each image is formatted as a\n",
        "    numpy ndarray with dimensions IMG_WIDTH x IMG_HEIGHT x 3. `labels` should\n",
        "    be a list of integer labels, representing the categories for each of the\n",
        "    corresponding `images`.\n",
        "    \"\"\"\n",
        "    images = list()\n",
        "    labels = list()\n",
        "    # get currend directory\n",
        "    workingDirectory = os.getcwd()\n",
        "    # add them together\n",
        "    path = workingDirectory + os.sep + data_dir\n",
        "    print(path)\n",
        "    # loop over all the directories\n",
        "    for dirpath, dirnames, filenames in os.walk(path):\n",
        "        if(filenames != ['.DS_Store']):\n",
        "            # loops over all the files inside the directory\n",
        "            for curFile in filenames:\n",
        "                file = dirpath + os.sep + curFile\n",
        "                # reads the image\n",
        "                image = cv2.imread(file)\n",
        "                # rezeises the image\n",
        "                resized = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT),\n",
        "                                     interpolation=cv2.INTER_AREA)\n",
        "                # make the input better for the neural network\n",
        "                if(NORMALIZE):\n",
        "                    resized = resized / 255.0\n",
        "                # add to pictures\n",
        "                images.append(resized)\n",
        "                # add to labels\n",
        "                labels.append(dirpath.replace(path + os.sep, \"\"))\n",
        "    return(images, labels)\n",
        "\n",
        "\n",
        "def get_model():\n",
        "    \"\"\"\n",
        "    Returns a compiled convolutional neural network model. Assume that the\n",
        "    `input_shape` of the first layer is `(IMG_WIDTH, IMG_HEIGHT, 3)`.\n",
        "    The output layer should have `NUM_CATEGORIES` units, one for each category.\n",
        "    \"\"\"\n",
        "    INPUT_SHAPE = (IMG_WIDTH, IMG_HEIGHT, 3)\n",
        "    # bias\n",
        "    model = tf.keras.models.Sequential([\n",
        "        # add the convolution layer\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\",\n",
        "                               input_shape=INPUT_SHAPE),\n",
        "        # use pooling\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        # add another concolutional layer\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
        "        # pool again\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        # generate a form as an input layer\n",
        "        tf.keras.layers.Flatten(),\n",
        "        # dense all are connected -> smaller then the imput layer\n",
        "        tf.keras.layers.Dense(HIDDENLAYERS_SIZE, activation='relu'),\n",
        "        # add a dropout\n",
        "        tf.keras.layers.Dropout(DROPOUT),\n",
        "        # add the output layer\n",
        "        tf.keras.layers.Dense(NUM_CATEGORIES, \"softmax\")\n",
        "    ])\n",
        "    # compile the model\n",
        "    model.compile(\n",
        "        optimizer=\"adam\",\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}